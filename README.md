# Automated Bone Age Estimation Using Deep Learning

A deep learning-based system for automated pediatric bone age estimation using hand X-ray images with Xception architecture and transfer learning.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Key Features](#key-features)
- [Performance Metrics](#performance-metrics)
- [Dataset](#dataset)
- [Model Architecture](#model-architecture)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Results](#results)
- [Team](#team)
- [Acknowledgments](#acknowledgments)

## ğŸ¯ Overview

Bone age assessment is a critical diagnostic tool for evaluating skeletal maturity and diagnosing growth disorders in children. Traditional manual methods are time-consuming and subject to inter-observer variability (Â±6-12 months). This project implements an automated bone age prediction system using deep learning to achieve clinically acceptable accuracy.

**Key Achievements:**
- ğŸ“Š **RÂ² Score: 0.9169** (target: â‰¥0.92)
- ğŸ“‰ **MAE: 9.04 months** (target: â‰¤12 months)
- âš–ï¸ **Low Gender Bias**: <2 months MAE difference between genders
- ğŸ¯ **91.54% Classification Accuracy** for developmental stages

## âœ¨ Key Features

- **Transfer Learning**: Leverages Xception architecture pre-trained on ImageNet
- **Gender-Aware Prediction**: Incorporates patient sex as input for improved accuracy
- **Model Explainability**: Grad-CAM visualization shows anatomically-correct attention on carpal bones and growth plates
- **Comprehensive Analysis**: 
  - Regression performance metrics
  - Gender bias analysis
  - Developmental stage classification (Child/Adolescent/Adult)
  - Error pattern analysis
- **Mixed Precision Training**: Optimized for RTX 3060 12GB GPU
- **Robust Preprocessing**: Architecture-specific preprocessing with data augmentation

## ğŸ“Š Performance Metrics

### Regression Performance
| Metric | Value |
|--------|-------|
| RÂ² Score | 0.9169 |
| MAE (Mean Absolute Error) | 9.04 months |
| RMSE | 11.75 months |
| Within Â±12 months | 91.5% |

### Classification Performance
| Metric | Value |
|--------|-------|
| Overall Accuracy | 91.54% |
| Quadratic Weighted Kappa (QWK) | 0.8248 |
| Child (0-10y) Recall | 95% |
| Adolescent (10-18y) Recall | 91% |

### Gender Bias Analysis
- MAE Difference: <2 months between male/female samples
- RÂ² Difference: <0.01
- **Fair predictions across both genders** âœ“

## ğŸ“ Dataset

**RSNA Pediatric Bone Age Challenge Dataset**
- **Total Images**: 12,611 hand X-ray images
- **Age Range**: 1-228 months (0-19 years)
- **Modality**: Left hand radiographs
- **Metadata**: Ground truth bone age + patient sex
- **Split**: 70% training / 15% validation / 15% test (stratified by age)

## ğŸ—ï¸ Model Architecture

### Xception Base Model
- **Architecture**: 36 convolutional layers with depthwise separable convolutions
- **Pre-training**: ImageNet weights
- **Innovation**: Efficient feature extraction through extreme Inception modules
- **Training Strategy**: All layers trainable from start (not frozen)

### Regression Head
```
Xception Base (256Ã—256Ã—3 input)
    â†“
GlobalMaxPooling2D
    â†“
Flatten
    â†“
Dense(10, ReLU)
    â†“
Dense(1, linear) â†’ Bone Age (months)
```

### Training Configuration
- **Input Size**: 256Ã—256 pixels
- **Preprocessing**: `xception.preprocess_input()` ([-1, 1] scaling)
- **Batch Size**: 4 (memory constraint)
- **Optimizer**: Adam (lr=0.001)
- **Loss Function**: Mean Squared Error (MSE)
- **Early Stopping**: Patience=7 epochs
- **Epochs**: 50 max (converged at epoch 18)
- **Mixed Precision**: FP16 for memory efficiency

## ğŸ› ï¸ Installation

### Prerequisites
```bash
Python 3.8+
CUDA 11.2+ (for GPU support)
```

### Dependencies
```bash
pip install tensorflow>=2.8.0
pip install numpy pandas matplotlib seaborn
pip install scikit-learn opencv-python
pip install jupyter notebook
```

### Clone Repository
```bash
git clone https://github.com/YOUR_USERNAME/bone-age-estimation.git
cd bone-age-estimation
```

## ğŸš€ Usage

### Training the Model
```python
# Open the main notebook
jupyter notebook Bone_Age_Prediction_Xception_FINAL.ipynb

# Or run directly
python train_model.py  # If you create a standalone script
```

### Making Predictions
```python
from tensorflow.keras.models import load_model
from tensorflow.keras.applications.xception import preprocess_input
import cv2

# Load model
model = load_model('best_model.h5')

# Load and preprocess image
img = cv2.imread('xray_image.png')
img = cv2.resize(img, (256, 256))
img = preprocess_input(img)
img = np.expand_dims(img, axis=0)

# Predict (with gender: 0=female, 1=male)
gender = 1  # male
prediction = model.predict([img, np.array([[gender]])])
print(f"Predicted Bone Age: {prediction[0][0]:.2f} months")
```

## ğŸ“‚ Project Structure

```
bone-age-estimation/
â”‚
â”œâ”€â”€ Bone_Age_Prediction_Xception_FINAL.ipynb  # Main implementation notebook
â”œâ”€â”€ README.md                                   # Project documentation
â”œâ”€â”€ requirements.txt                            # Python dependencies
â”œâ”€â”€ .gitignore                                  # Git ignore rules
â”‚
â”œâ”€â”€ Bone_age_prediction/                        # Output visualizations
â”‚   â”œâ”€â”€ training_history.png                    # Training curves
â”‚   â”œâ”€â”€ prediction_scatter.png                  # Predicted vs actual
â”‚   â”œâ”€â”€ confusion_matrix.png                    # Classification results
â”‚   â””â”€â”€ gradcam_*.png                           # Grad-CAM visualizations
â”‚
â”œâ”€â”€ docs/                                       # Documentation files
â”‚   â”œâ”€â”€ Bone_Age_Report_Fixed.tex              # LaTeX report source
â”‚   â”œâ”€â”€ Bone_Age_Presentation.tex              # LaTeX presentation
â”‚   â”œâ”€â”€ PRML_COURSE_PROJECT_Final.pdf          # Final report PDF
â”‚   â””â”€â”€ PRML_PROJECT_PRESENTATION.pdf          # Presentation slides
â”‚
â””â”€â”€ models/                                     # Saved model weights
    â””â”€â”€ best_xception_model.h5                 # Best trained model
```

## ğŸ“ˆ Results

### Approach Comparison
We experimented with multiple approaches before achieving optimal results:

| Approach | RÂ² Score | MAE (months) | Notes |
|----------|----------|--------------|-------|
| EfficientNet-B4 (frozen) | 0.70 | 33 | Insufficient adaptation |
| Xception + CLAHE | -0.01 | N/A | Preprocessing broke transfer learning |
| Xception + ROI crop | 0.68 | 28 | Lost contextual information |
| **Our Final Model** | **0.9169** | **9.04** | **All layers trainable** âœ“ |

### Key Insights
1. **Architecture-specific preprocessing is critical** - Using `xception.preprocess_input()` was essential
2. **Training all layers from start** outperformed gradual unfreezing approach
3. **Contrast enhancement (CLAHE) breaks transfer learning** from ImageNet weights
4. **Simple regression heads** (10 units) work well with strong base models

### Visualizations

**Predicted vs Actual Age**
- Strong linear correlation (RÂ²=0.9169)
- Most predictions within Â±12 months clinical threshold

**Residual Plot**
- Errors centered around zero
- Slight heteroscedasticity at age extremes

**Grad-CAM Attention**
- Model correctly focuses on carpal bones and epiphyseal growth plates
- Validates medically-correct feature learning

**Gender Bias Analysis**
- Minimal performance difference between male/female samples
- Fair and unbiased predictions

## ğŸ‘¥ Team

**Pattern Recognition and Machine Learning Course Project**

- **Amit Anil Kamble** - CS23B2034
- **Jatin Goyal** - CS23B2045
- **Sumit Kumar** - CS23B2008

**Guided By:**  
Dr. Umarani Jayaraman, Assistant Professor

## ğŸ“ Acknowledgments

- **RSNA** for providing the Pediatric Bone Age Challenge dataset
- **Keras Applications** for pre-trained Xception weights
- **TensorFlow** team for the deep learning framework
- Course instructors and peers for valuable feedback

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“š References

1. Halabi, S. S., et al. (2019). "The RSNA Pediatric Bone Age Machine Learning Challenge." *Radiology*.
2. Chollet, F. (2017). "Xception: Deep Learning with Depthwise Separable Convolutions." *CVPR*.
3. Selvaraju, R. R., et al. (2017). "Grad-CAM: Visual Explanations from Deep Networks." *ICCV*.

## ğŸ“§ Contact

For questions or collaborations:
- GitHub: [@AmitAK1](https://github.com/AmitAK1)
- Email: cs23b2034@iittp.ac.in

---

**â­ If you find this project useful, please consider giving it a star!**
